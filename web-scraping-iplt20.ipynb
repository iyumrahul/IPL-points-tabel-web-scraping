{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Scraping IPL(Indian Premier League) Points Table using Selenium & Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The Indian Premier League (IPL), also officially known as TATA IPL for sponsorship reasons, is a professional men's Twenty20 cricket league, contested by ten teams based out of seven Indian cities and three Indian states.[1][2] The league was founded by the Board of Control for Cricket in India (BCCI) in 2007. \n",
    "\n",
    "IPL 2023 is about to kick off in a few months and just like every season data science enthusiasts must be itching to get their hands on match data to slice and dice the data with an intent to gain insights in to the teams/players and the more ambitious of the lot would look to predict the results of these games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://assets.iplt20.com/bcci/articles/1662579908_np-iplImg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  What is Web Scraping?\n",
    "\n",
    "Web Scraping gives us the ability to collect data from a source all by ourselves and in the format that we would like Of course there would be some limitations depending on the source of the data but we have greater control since we get to decide how and what data we scrape from the data available at the source.\n",
    "We would be using iplt20.com to scrape the points tables as they are kind enough to allow scraping with some restrictions. We would work on IPL data.\n",
    "\n",
    "The below infographic gives a gist of how we would be approaching this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![](https://i.imgur.com/HUwa4dj.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of the Project:\n",
    "\n",
    "1. Understanding the structure of iplt20.com Website.\n",
    "2. Installing and Importing required libraries.\n",
    "3. Simulating the page and Extracting the URLs of all the years from website using selenium.\n",
    "4. Accessing each year and building a URL (Total 15 years as shown in the above figure).\n",
    "5. Parsing the points table details into 13 fields: Year,Position,Team,played,won,lost,tied,no result,net run rate, for,      against,points form using Helper Functions.\n",
    "6. Storing the extracted data into a dictionary.\n",
    "7. Compiling all the data into a DataFrame using Pandas and saving the data into CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of the project weâ€™ll create DataFrame in the following format .\n",
    "## ![](https://i.imgur.com/eMAW51z.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The selenium web driver is hosted on the replit server to run the below code, open the below link to run the code.\n",
    "\n",
    "https://replit.com/@iyumrahul/selinium-iplt20-Scraping#main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps followed:\n",
    "We have broken down into 3 steps:-\n",
    "\n",
    "1. First we would extract all the year links from the homepage for IPL. We would use selenium to gather all these links.\n",
    "\n",
    "2. We would navigate all the tags and scrape the points table one by one using the functions.\n",
    "\n",
    "3. Since we already have all inner and outer tags, we will navigate to the data in the points table page and scrape the details by calling the functions into dictionary and save it to a dataframe and finally export it to a csv file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We would move on to the code now. For the two steps we mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and impoert required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"gowdarahul54/web-scraping-iplt20\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/gowdarahul54/web-scraping-iplt20\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (1.3.3)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement as (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for as\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "import jovian\n",
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"web-scraping-iplt20\")\n",
    "\n",
    "!pip install selenium --upgrade --quiet\n",
    "!pip install pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering the infomation of all the years ipl was conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year list\n",
    "\n",
    "year_list = [2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019,2020, 2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining functions to get all the links\n",
    "\n",
    "def get_url(year):\n",
    "    base_url, input = 'https://www.iplt20.com/points-table/men/', str(year)\n",
    "    ipl_pointsTable_url = base_url + input\n",
    "    return ipl_pointsTable_url\n",
    "def url_of_years():\n",
    "    URL=[]\n",
    "    for years in year_list:\n",
    "        URL.append(get_url(years))\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=url_of_years()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Selenium webdriver to navigate to a web page, with Webdriver the browser loads all the resources of the website (JavaScript files, images, CSS, files, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating Driver')\n",
    "driver = get_driver()\n",
    "print('Feteching the page')\n",
    "print('Page title:', driver.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions to get tags\n",
    "    \n",
    "def get_outer_tag():\n",
    "    outer_tag = driver.find_elements(By.CLASS_NAME, 'ih-pt-tab-bg')\n",
    "    outerTag = outer_tag[0]\n",
    "    inner_tag = outerTag.find_elements(By.CLASS_NAME, 'team0')\n",
    "    return inner_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of position column\n",
    "def get_position_col():\n",
    "    tags = get_outer_tag()\n",
    "    Place = []\n",
    "    for i in tags:\n",
    "        place = i.find_elements(By.TAG_NAME, 'td')[0].text\n",
    "        Place.append(place)\n",
    "    dreturn Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of teams column\n",
    "def get_Team_col():\n",
    "    tags = get_outer_tag()\n",
    "    Team = []\n",
    "    for i in tags:\n",
    "        team = i.find_elements(By.TAG_NAME, 'td')[1].text\n",
    "        Team.append(team)\n",
    "    return Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of matches played column\n",
    "def get_Pld_col():\n",
    "    tags = get_outer_tag()\n",
    "    Pld = []\n",
    "    for i in tags:\n",
    "        pld = i.find_elements(By.TAG_NAME, 'td')[2].text\n",
    "        Pld.append(pld)\n",
    "    return Pld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of matches won column\n",
    "def get_Won_col():\n",
    "    tags = get_outer_tag()\n",
    "    Won = []\n",
    "    for i in tags:\n",
    "        won = i.find_elements(By.TAG_NAME, 'td')[3].text\n",
    "        Won.append(won)\n",
    "    return Won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of matches lost column\n",
    "def get_Lost_col():\n",
    "    tags = get_outer_tag()\n",
    "    Lost = []\n",
    "    for i in tags:\n",
    "        lost = i.find_elements(By.TAG_NAME, 'td')[4].text\n",
    "        Lost.append(lost)\n",
    "    return Lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of matches tied column\n",
    "def get_Tied_col():\n",
    "    tags = get_outer_tag()\n",
    "    Tied = []\n",
    "    for i in tags:\n",
    "        tied = i.find_elements(By.TAG_NAME, 'td')[5].text\n",
    "        Tied.append(tied)\n",
    "    return Tied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of matches ended with no results column\n",
    "def get_No_Result_col():\n",
    "    tags = get_outer_tag()\n",
    "    No_Result = []\n",
    "    for i in tags:\n",
    "        noResult = i.find_elements(By.TAG_NAME, 'td')[6].text\n",
    "        No_Result.append(noResult)\n",
    "    return No_Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of net run rate column\n",
    "def get_Net_RR_col():\n",
    "    tags = get_outer_tag()\n",
    "    Net_RR = []\n",
    "    for i in tags:\n",
    "        net_rr = i.find_elements(By.TAG_NAME, 'td')[7].text\n",
    "        Net_RR.append(net_rr)\n",
    "    return Net_RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of column having score over the number of overs played for \n",
    "def get_For_col():\n",
    "    tags = get_outer_tag()\n",
    "    _For = []\n",
    "    for i in tags:\n",
    "        _for = i.find_elements(By.TAG_NAME, 'td')[8].text\n",
    "        _For.append(_for)\n",
    "    return _For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of column having score over the number of overs played against \n",
    "def get_Against_col():\n",
    "    tags =get_outer_tag()\n",
    "    Against = []\n",
    "    for i in tags:\n",
    "        against = i.find_elements(By.TAG_NAME, 'td')[9].text\n",
    "        Against.append(against)\n",
    "    return Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of points column\n",
    "def get_Pts_col():\n",
    "    tags = get_outer_tag()\n",
    "    Pts = []\n",
    "    for i in tags:\n",
    "        points = i.find_elements(By.TAG_NAME, 'td')[10].text\n",
    "        Pts.append(points)\n",
    "    return Pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of column having last 5 games \n",
    "def get_Form_col():\n",
    "    tags = get_outer_tag()\n",
    "    Form = []\n",
    "    for i in tags:\n",
    "        form = i.find_elements(By.TAG_NAME,'td')[11].text.replace('\\n','')\n",
    "        Form.append(form)\n",
    "    return Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definig a function to get the details of year column\n",
    "def get_year_col(year):\n",
    "    Year=[]\n",
    "    for i in year:\n",
    "        if i==2022 or i==2011:\n",
    "            for j in range(10):\n",
    "                Year.append(i)\n",
    "        elif i==2012 or i==2013:\n",
    "            for j in range(9):\n",
    "                Year.append(i)  \n",
    "        else:\n",
    "            for j in range(8):\n",
    "                Year.append(i)   \n",
    "    return Year\n",
    "\n",
    "Years=get_year_col(year_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the main function to call all the other functions into dictonaries\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def get_data(url,years):\n",
    "    dictonary={'Year':years,'position_column':[],'Team': [],'Pld':[],'Won': [],'Lost':[],'Tied':[],\n",
    "               'No_result': [],'Net_RR': [],'For': [],'Against': [],'Points':[],'Form':[] }\n",
    "    for i in url:\n",
    "        driver.get(i)\n",
    "        dictonary['position_column'].extend(get_position_col())\n",
    "        dictonary['Team'].extend(get_Team_col())\n",
    "        dictonary['Pld'].extend(get_Pld_col())\n",
    "        dictonary['Won'].extend( get_Won_col())\n",
    "        dictonary['Lost'].extend(get_Lost_col())\n",
    "        dictonary['Tied'].extend(get_Tied_col())\n",
    "        dictonary['No_result'].extend( get_No_Result_col())\n",
    "        dictonary['Net_RR'].extend(get_Net_RR_col())\n",
    "        dictonary['For'].extend(get_For_col())\n",
    "        dictonary['Against'].extend(get_Against_col())\n",
    "        dictonary['Points'].extend(get_Pts_col())\n",
    "        dictonary['Form'].extend(get_Form_col())\n",
    "    return dictonary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The final step to get the extracted data into csv formate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the resulting out put in a variable\n",
    "dictonary_data = get_data(url,Years)\n",
    "\n",
    "# dataframe to get data of year 2022-points tabel in tablur form\n",
    "df = pd.DataFrame(dictonary_data)\n",
    "\n",
    "# the dataframe is then converted into csv file\n",
    "df.to_csv('IPLT20-points-Tabel.csv', index=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We place a webpage url request using selenium webdriver\n",
    "\n",
    "- The Scraping was done using Python libraries such as Selenium for extracting the data,pandas for dataframe.\n",
    "\n",
    "- Scraping points table details since past 15 years from iplt20.com website into 13 fields like Year,Position,Team,played,won,lost,tied,no result,net run rate, for,against,points form using Helper Functions.\n",
    "\n",
    "- Parsed all the scraped data into a csv file containing total of 126 rows and 13 columns for every year since 2008 since we have data in the in dictonary  We flatten the data into tabular form.\n",
    "\n",
    "- Post that we pre process the data as per our requirement and finally export the processed data to IPLT20-points-Table.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting more details of the project and creator by accessing the project links and creator links\n",
    "Code optimization\n",
    "\n",
    "- Improving the documentation part of the project\n",
    "\n",
    "- The data collection here can be improved vastly by in future by appending the years into the year list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IPLt20 Homepage:- https://www.iplt20.com/points-table/men/2022\n",
    "\n",
    "- Selenium Documentation:- https://www.selenium.dev/selenium/docs/api/py/api.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
